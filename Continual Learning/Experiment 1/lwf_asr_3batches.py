# -*- coding: utf-8 -*-
"""LWF ASR_3batches.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NwmGzYnRN6BNsyYgoXCPgiHepdP-XjFj

3 batches- used for LWF analysis, accuracy vs lambda for diff batches
"""

!pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
import IPython.display as ipd
from tqdm.notebook import tqdm
import random
torch.manual_seed(0)
np.random.seed(0)
random.seed(0)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

"""
import urllib.request

url = 'https://www.cse.iitb.ac.in/~pjyothi/cs753/train_list.txt'
urllib.request.urlretrieve(url, 'train_list.txt')
train_indices = open("/content/train_list.txt").read().splitlines()#.readlines()
train_indices = [int(i) for i in train_indices]
#print(train_indices)
url = 'https://www.cse.iitb.ac.in/~pjyothi/cs753/test_list.txt'
urllib.request.urlretrieve(url, 'test_list.txt')
test_indices = open("/content/test_list.txt").read().splitlines()
test_indices = [int(i) for i in test_indices]
#print(test_indices)
"""

from torchaudio.datasets import SPEECHCOMMANDS
import os
class SubsetSC(SPEECHCOMMANDS):
    def __init__(self, subset: str = None):
        super().__init__("./", download=True)

        def load_list(filename):
            filepath = os.path.join(self._path, filename)
            with open(filepath) as fileobj:
                return [os.path.join(self._path, line.strip()) for line in fileobj]

        if subset == "testing":
            self._walker = load_list("testing_list.txt")
            print("Size of original test set:",len(self._walker))
            #self._walker = [self._walker[i] for i in test_indices]
            #print("Size of new test set:",len(self._walker))
        elif subset == "training":
            excludes = load_list("validation_list.txt") + load_list("testing_list.txt")
            excludes = set(excludes)
            self._walker = [w for w in self._walker if w not in excludes]
            print("Size of original train set:",len(self._walker))
            #self._walker = [self._walker[i] for i in train_indices]
            #print("Size of new train set:",len(self._walker))


# Create training and testing split of the data. We do not use validation in this tutorial.
training_list = SubsetSC("training")
testing_list = SubsetSC("testing")

"""Model A: 12 classes"""

import os
classes = os.listdir("/content/SpeechCommands/speech_commands_v0.02/")
classes.remove("LICENSE")
classes.remove("README.md")
classes.remove("_background_noise_")
classes.remove("testing_list.txt")
classes.remove("validation_list.txt")
classes.remove(".DS_Store")
print(classes)
classes_A = classes[:12]
print("Number of classes", len(classes_A))
print(classes_A)

import glob
"""
## Read the test list
with open("/content/SpeechCommands/speech_commands_v0.02/testing_list.txt") as testing_f:
  testing_list = [x.strip() for x in testing_f.readlines()]

print(len(testing_list))
testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_list))
#print("Number of validation samples", len(validation_list))
"""
## Construct a train list
training_list = []

def load_list(filename):
  filepath = os.path.join("/content/SpeechCommands/speech_commands_v0.02/", filename)
  with open(filepath) as fileobj:
    return [os.path.join("/content/SpeechCommands/speech_commands_v0.02/", line.strip()) for line in fileobj]

testing_list = load_list("testing_list.txt")
print(len(testing_list))
testing_listA = [testing_list[i] for i in range(len(testing_list)) if testing_list[i].split("/")[4] in classes_A ]
#testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_listA))

excludes = load_list("testing_list.txt") + load_list("validation_list.txt")
excludes = set(excludes)

for c in classes:
  training_list += glob.glob("/content/SpeechCommands/speech_commands_v0.02/" + c + "/*")

training_list = [w for w in training_list if w not in excludes]
training_listA = [training_list[i] for i in range(len(training_list)) if training_list[i].split("/")[4] in classes_A ]

print("Number of training samples", len(training_listA))

print(testing_listA)

class SpeechDataset(SPEECHCOMMANDS):
  
  def __init__(self, classes, file_list):
    super().__init__("/content/", download=True)
    
    self.classes = classes
    
    # create a map from class name to integer
    self.class_to_int = dict(zip(classes, range(len(classes))))
    
    # store the file names
    self.samples = file_list
    #print(self.samples[0])
    
    # store our MFCC transform
    self.mfcc_transform = torchaudio.transforms.MFCC(n_mfcc=12, log_mels=True)
    
  def __len__(self):
    return len(self.samples)
    
  def __getitem__(self,i):
    with torch.no_grad():
      # load a normalized waveform
      waveform,_ = torchaudio.load(self.samples[i], normalization=True)
      
      # if the waveform is too short (less than 1 second) we pad it with zeroes
      if waveform.shape[1] < 16000:
        waveform = F.pad(input=waveform, pad=(0, 16000 - waveform.shape[1]), mode='constant', value=0)
      
      # then, we apply the transform
      mfcc = self.mfcc_transform(waveform).squeeze(0).transpose(0,1)
    
    # get the label from the file name
    label = self.samples[i].split("/")[4]
    
    # return the mfcc coefficient with the sample label
    return mfcc, self.class_to_int[label]

train_setA = SpeechDataset(classes_A, training_listA)
val_setA =SpeechDataset(classes_A, testing_listA)

print(train_setA[5][0].shape)

train_dlA = torch.utils.data.DataLoader(train_setA, batch_size=32, shuffle=True)
val_dlA = torch.utils.data.DataLoader(val_setA, batch_size=32)

#print(next(iter(train_dl)))

class CNNLayerNorm(nn.Module):
    def __init__(self, n_feats):
        super(CNNLayerNorm, self).__init__()
        self.layer_norm = nn.LayerNorm(n_feats)

    def forward(self, x):
        # x (batch, channel, feature, time)
        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)
        x = self.layer_norm(x)
        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)

class SpeechRNN(torch.nn.Module):
   
  def __init__(self,kernel = 3, stride = 1, dropout = 0.1, n_feats = 128):#original dropout = 0.5
    super(SpeechRNN, self).__init__()

    self.conv1 = torch.nn.Conv2d(1, 32, kernel, stride, padding = kernel//2)
    #Introduce residual connection here
    #self.layer_norm1 = CNNLayerNorm(n_feats)
    self.layer_norm1 = nn.BatchNorm2d(32)
    self.dropout1 = nn.Dropout(dropout)
    self.conv2 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #self.layer_norm2 = CNNLayerNorm(n_feats)
    self.layer_norm2 = nn.BatchNorm2d(32)
    self.dropout2 = nn.Dropout(dropout)
    self.conv3 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #Introduce residual connection here
    #self.layer_norm3 = CNNLayerNorm(n_feats)
    self.layer_norm3 = nn.BatchNorm2d(32)
    self.dropout3 = nn.Dropout(dropout)
    self.conv4 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #self.layer_norm4 = CNNLayerNorm(n_feats)
    self.layer_norm4 = nn.BatchNorm2d(32)
    self.dropout4 = nn.Dropout(dropout)
    self.conv5 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #self.bn5 = nn.BatchNorm2d(32)
    self.dropout5 = nn.Dropout(dropout)

    self.linear = nn.Linear(972*32,256)

    #self.layer_norm5 = nn.LayerNorm(256)

    self.linear1 = torch.nn.Linear(256, 256)
    #self.dropout6 = nn.Dropout(dropout)
    #self.linear2 = torch.nn.Linear(256, len(classes))
    
  def forward(self, x):
    x = x.unsqueeze(1)
    x = self.conv1(x)
    residual = x
    x = self.layer_norm1(x)
    x = F.leaky_relu(x)
    x = self.dropout1(x)
    x = self.conv2(x)
    x = self.layer_norm2(x)
    x = F.leaky_relu(x)
    x = self.dropout2(x)
    x = self.conv3(x)
    x = x + residual

    residual1 = x
    x = self.layer_norm3(x)
    x = F.leaky_relu(x)
    x = self.dropout3(x)
    x = self.conv4(x)
    x = self.layer_norm4(x)
    x = F.leaky_relu(x)
    x = self.dropout4(x)
    x = self.conv5(x)
    x = x + residual1
    #print(x.size())

    sizes = x.size()
    x = x.view(sizes[0], sizes[1]*sizes[2]*sizes[3])
    #x = x.transpose(1,2)
    #print(x.size())
    x = self.linear(x)

    #x = self.layer_norm5(x)
    x = F.leaky_relu(x)

    x = self.linear1(x)
    x = F.leaky_relu(x)
    #x = self.dropout6(x)
    #x = self.linear2(x)
    #print(x.size())
    
    return x

class ModelA(nn.Module):
  def __init__(self,classes):
    super(ModelA,self).__init__()
    self.speech_model = SpeechRNN()
    self.final_layer = torch.nn.Linear(256, len(classes))
  
  def forward(self,x):
    x = self.speech_model(x)
    x = self.final_layer(x)
    return x

#net = SpeechRNN().cuda()
netA = ModelA(classes = classes_A).cuda()
print(netA)
batch = next(iter(train_dlA))[0]
print(batch.shape)
y = netA(batch.cuda())

print(y.shape)

##RE-RUN THIS CODE TO GET A "NEW" NETWORK

LEARNING_RATE = 0.0005

## Create an instance of our network
netA = ModelA(classes = classes_A).cuda()

# Negative log likelihood loss
criterion = torch.nn.CrossEntropyLoss()

# Adam optimizer
optimizer = torch.optim.Adam(netA.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

from tqdm import tqdm_notebook
## NUMBER OF EPOCHS TO TRAIN
N_EPOCHS = 10

epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []

for e in range(N_EPOCHS):
  
  print("EPOCH:",e)
  
  ### TRAINING LOOP
  running_loss = 0
  running_accuracy = 0
  
  ## Put the network in training mode
  netA.train()
  
  for i, batch in enumerate(tqdm_notebook(train_dlA)):
    
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]
    
    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netA(x)
    
    # Compute the loss
    loss = criterion(y, labels)
    
    # Reset the gradients
    optimizer.zero_grad()
    
    # Compute the gradients
    loss.backward()
    
    # Apply one step of the descent algorithm to update the weights
    optimizer.step()
    
    ## Compute some statistics
    with torch.no_grad():
      running_loss += loss.item()
      running_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Training accuracy:", running_accuracy/float(len(train_setA)),
        "Training loss:", running_loss/float(len(train_setA)))
  
  epoch_loss.append(running_loss/len(train_setA))
  epoch_acc.append(running_accuracy/len(train_setA))
  
  ### VALIDATION LOOP
  ## Put the network in validation mode
  netA.eval()
  
  running_val_loss = 0
  running_val_accuracy = 0

  for i, batch in enumerate(val_dlA):
    
    with torch.no_grad():
      # Get a batch from the dataloader
      x = batch[0]
      labels = batch[1]

      # move the batch to GPU
      x = x.cuda()
      labels = labels.cuda()

      # Compute the network output
      y= netA(x)
      
      # Compute the loss
      loss = criterion(y, labels)
      
      running_val_loss += loss.item()
      running_val_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Validation accuracy:", running_val_accuracy/float(len(val_setA)),
        "Validation loss:", running_val_loss/float(len(val_setA)))
  
  epoch_val_loss.append(running_val_loss/len(val_setA))
  epoch_val_acc.append(running_val_accuracy/len(val_setA))

import numpy  as np
# Create a test dataset instance
test_datasetA = SpeechDataset(classes_A, testing_listA)

# Create a DataLoader
test_dlA = torch.utils.data.DataLoader(test_datasetA, batch_size=64)

netA.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(test_dlA):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netA(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_datasetA)),
      "Test loss:", test_loss/float(len(test_datasetA)))

print(netA)

torch.save(netA.state_dict(),'modelA.pth')
torch.save(netA,'modelA.pt')

"""Model B: 12 classes"""

classes_B =classes[12:24]
print("Number of classes", len(classes_B))
print(classes_B)

import glob
"""
## Read the test list
with open("/content/SpeechCommands/speech_commands_v0.02/testing_list.txt") as testing_f:
  testing_list = [x.strip() for x in testing_f.readlines()]

print(len(testing_list))
testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_list))
#print("Number of validation samples", len(validation_list))
"""
## Construct a train list
training_list = []

def load_list(filename):
  filepath = os.path.join("/content/SpeechCommands/speech_commands_v0.02/", filename)
  with open(filepath) as fileobj:
    return [os.path.join("/content/SpeechCommands/speech_commands_v0.02/", line.strip()) for line in fileobj]

testing_list = load_list("testing_list.txt")
print(len(testing_list))
testing_listB = [testing_list[i] for i in range(len(testing_list)) if testing_list[i].split("/")[4] in classes_B ]
#testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_listB))

excludes = load_list("testing_list.txt") + load_list("validation_list.txt")
excludes = set(excludes)

for c in classes:
  training_list += glob.glob("/content/SpeechCommands/speech_commands_v0.02/" + c + "/*")

training_list = [w for w in training_list if w not in excludes]
training_listB = [training_list[i] for i in range(len(training_list)) if training_list[i].split("/")[4] in classes_B ]
print(training_listB[0])
print(testing_listB[0])
#training_list = [training_list[i] for i in train_indices]

print("Number of training samples", len(training_listB))

train_setB = SpeechDataset(classes_B, training_listB)
val_setB =SpeechDataset(classes_B, testing_listB)

print(train_setB[5][0].shape)

train_dlB = torch.utils.data.DataLoader(train_setB, batch_size=32, shuffle=True)
val_dlB = torch.utils.data.DataLoader(val_setB, batch_size=32)

#print(next(iter(train_dl)))

class ModelB(nn.Module):
  def __init__(self,classes):
    super(ModelB,self).__init__()
    self.speech_model = SpeechRNN()
    self.final_layer = torch.nn.Linear(256, len(classes))
  
  def forward(self,x):
    x = self.speech_model(x)
    x = self.final_layer(x)
    return x

netB = ModelB(classes = classes_B).cuda()

checkpointA = torch.load('modelA.pt')
pretrainedA_dict = checkpointA.speech_model.state_dict()
netB_dict = netB.speech_model.state_dict()
"""
for key,_ in pretrained_dict.items():
  print(key)
print("/n")
for key,_ in net1_dict.items():
  print(key)
"""
pretrainedA_dict = {k: v for k, v in pretrainedA_dict.items() if k in netB_dict}
netB_dict.update(pretrainedA_dict)
#net1_dict=pretrained_dict
#print(net1_dict)
netB.speech_model.load_state_dict(netB_dict)#, strict=False)

from copy import deepcopy
from torch.autograd import Variable
from torch.nn import functional as F

def ewc_penalty(old_model:nn.Module, dataset:torch.utils.data.DataLoader):

  params = {n:p for n,p in old_model.named_parameters() if p.requires_grad}
  means = {}
  for n,p in deepcopy(params).items():
    means[n] = Variable(p.data).cuda()
  precision_matrices = {}
  for n,p in deepcopy(params).items():
    p.data.zero_()
    precision_matrices[n] = Variable(p.data).cuda()
  old_model.eval()
  for inp,_ in dataset:
    old_model.zero_grad()
    inp = Variable(inp).cuda()
    #print(old_model(inp))
    output = old_model(inp).view(1,-1)
    label = output.max(1)[1].view(-1)
    #print(label)
    loss = F.nll_loss(F.log_softmax(output,dim=1),label)
    loss.backward()

    for n,p in old_model.named_parameters():
      precision_matrices[n].data+=p.grad.data**2/len(dataset)
  
  precision_matrices = {n:p for n,p in precision_matrices.items()}
  return precision_matrices, means

#for x,_ in old_train_dl:
#  print(x.shape)
prec,mat = ewc_penalty(checkpointA.speech_model, train_dlA)

def lwf(old_model: nn.Module, model:nn.Module,dataset:torch.utils.data.DataLoader):
  loss = 0
  inp = dataset
  #inp = Variable(dataset).cuda()
  #print(inp.shape)
  old_x = old_model(inp)
  x = model(inp)
  #print(x.shape)
  old_x = old_x.view(1,-1)
  x = x.view(1,-1)
  l = torch.dist(old_x,x,p=2)
  #print(l)
  loss+=l.item()
  
  return loss

"""Train model B"""

##RE-RUN THIS CODE TO GET A "NEW" NETWORK

LEARNING_RATE = 0.0005

# Negative log likelihood loss
criterion = torch.nn.CrossEntropyLoss()

# Adam optimizer
optimizer = torch.optim.Adam(netB.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

from tqdm import tqdm_notebook
## NUMBER OF EPOCHS TO TRAIN
N_EPOCHS = 10
lamda = 0.01
epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []

for e in range(N_EPOCHS):
  
  print("EPOCH:",e)
  
  ### TRAINING LOOP
  running_loss = 0
  running_accuracy = 0

  ## Put the network in training mode
  netB.train()
  
  for i, batch in enumerate(tqdm_notebook(train_dlB)):
    
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]
    
    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netB(x)
    """
    ewc_loss = 0
    for n,p in netB.speech_model.named_parameters():
      if p.requires_grad:
        l = prec[n[:]]*(p-mat[n[:]])**2
        ewc_loss +=l.sum()
    """
    lwf_loss = lwf(netA.speech_model,netB.speech_model,x)
    # Compute the loss
    loss = criterion(y, labels) + lamda*lwf_loss
    
    # Reset the gradients
    optimizer.zero_grad()
    
    # Compute the gradients
    loss.backward()
    
    # Apply one step of the descent algorithm to update the weights
    optimizer.step()
    
    ## Compute some statistics
    with torch.no_grad():
      running_loss += loss.item()
      running_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Training accuracy:", running_accuracy/float(len(train_setB)),
        "Training loss:", running_loss/float(len(train_setB)), "LWF Loss:", lwf_loss)
  
  epoch_loss.append(running_loss/len(train_setB))
  epoch_acc.append(running_accuracy/len(train_setB))
  
  ### VALIDATION LOOP
  ## Put the network in validation mode
  netB.eval()
  
  running_val_loss = 0
  running_val_accuracy = 0

  for i, batch in enumerate(val_dlB):
    
    with torch.no_grad():
      # Get a batch from the dataloader
      x = batch[0]
      labels = batch[1]

      # move the batch to GPU
      x = x.cuda()
      labels = labels.cuda()

      # Compute the network output
      y= netB(x)
      
      # Compute the loss
      loss = criterion(y, labels)
      
      running_val_loss += loss.item()
      running_val_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Validation accuracy:", running_val_accuracy/float(len(val_setB)),
        "Validation loss:", running_val_loss/float(len(val_setB)))
  
  epoch_val_loss.append(running_val_loss/len(val_setB))
  epoch_val_acc.append(running_val_accuracy/len(val_setB))

torch.save(netB, "modelB.pt")

"""Test model B"""

# Create a test dataset instance
test_datasetB = SpeechDataset(classes_B, testing_listB)

# Create a DataLoader
test_dlB = torch.utils.data.DataLoader(test_datasetB, batch_size=64)

netB.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(test_dlB):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netB(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_datasetB)),
      "Test loss:", test_loss/float(len(test_datasetB)))

"""Test model A"""

checkpointB = torch.load('modelB.pt')
pretrainedB_dict = checkpointB.speech_model.state_dict()
netA_dict = netA.speech_model.state_dict()
"""
for key,_ in pretrained_dict.items():
  print(key)
print("/n")
for key,_ in net1_dict.items():
  print(key)
"""
pretrainedB_dict = {k: v for k, v in pretrainedB_dict.items() if k in netA_dict}
netA_dict.update(pretrainedB_dict)
#net1_dict=pretrained_dict
#print(net1_dict)
netA.speech_model.load_state_dict(netA_dict)#, strict=False)

netA.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(test_dlA):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netA(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_datasetA)),
      "Test loss:", test_loss/float(len(test_datasetA)))

"""Model C: 11 classes"""

classes_C =classes[24:]
print("Number of classes", len(classes_C))
print(classes_C)

## Construct a train list
training_list = []

def load_list(filename):
  filepath = os.path.join("/content/SpeechCommands/speech_commands_v0.02/", filename)
  with open(filepath) as fileobj:
    return [os.path.join("/content/SpeechCommands/speech_commands_v0.02/", line.strip()) for line in fileobj]

testing_list = load_list("testing_list.txt")
print(len(testing_list))
testing_listC = [testing_list[i] for i in range(len(testing_list)) if testing_list[i].split("/")[4] in classes_C ]
#testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_listC))

excludes = load_list("testing_list.txt") + load_list("validation_list.txt")
excludes = set(excludes)

for c in classes:
  training_list += glob.glob("/content/SpeechCommands/speech_commands_v0.02/" + c + "/*")

training_list = [w for w in training_list if w not in excludes]
training_listC = [training_list[i] for i in range(len(training_list)) if training_list[i].split("/")[4] in classes_C ]
#training_list = [training_list[i] for i in train_indices]

print("Number of training samples", len(training_listC))

train_setC = SpeechDataset(classes_C, training_listC)
val_setC =SpeechDataset(classes_C, testing_listC)

print(train_setC[5][0].shape)

train_dlC = torch.utils.data.DataLoader(train_setC, batch_size=32, shuffle=True)
val_dlC = torch.utils.data.DataLoader(val_setC, batch_size=32)

class ModelC(nn.Module):
  def __init__(self,classes):
    super(ModelC,self).__init__()
    self.speech_model = SpeechRNN()
    self.final_layer = torch.nn.Linear(256, len(classes))
  
  def forward(self,x):
    x = self.speech_model(x)
    x = self.final_layer(x)
    return x

netC = ModelC(classes = classes_C).cuda()

checkpointB = torch.load('modelB.pt')
pretrainedB_dict = checkpointB.speech_model.state_dict()
netC_dict = netC.speech_model.state_dict()
pretrainedB_dict = {k: v for k, v in pretrainedB_dict.items() if k in netC_dict}
netC_dict.update(pretrainedB_dict)
#net1_dict=pretrained_dict
#print(net1_dict)
netC.speech_model.load_state_dict(netC_dict)#, strict=False)

"""Train Model C"""

prec,mat = ewc_penalty(checkpointB.speech_model, train_dlB)
##RE-RUN THIS CODE TO GET A "NEW" NETWORK

LEARNING_RATE = 0.0005
elambda = 30 #ewc lambda in loss function

# Negative log likelihood loss
criterion = torch.nn.CrossEntropyLoss()

# Adam optimizer
optimizer = torch.optim.Adam(netC.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

from tqdm import tqdm_notebook
## NUMBER OF EPOCHS TO TRAIN
N_EPOCHS = 10

epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []

for e in range(N_EPOCHS):
  
  print("EPOCH:",e)
  
  ### TRAINING LOOP
  running_loss = 0
  running_accuracy = 0

  ## Put the network in training mode
  netC.train()
  
  for i, batch in enumerate(tqdm_notebook(train_dlC)):
    
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]
    
    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netC(x)
    """
    ewc_loss = 0
    for n,p in netC.speech_model.named_parameters():
      if p.requires_grad:
        l = prec[n[:]]*(p-mat[n[:]])**2
        ewc_loss +=l.sum()
    """
    lwf_loss = lwf(netB.speech_model, netC.speech_model, x)
    # Compute the loss
    loss = criterion(y, labels) + lamda*lwf_loss
    
    # Reset the gradients
    optimizer.zero_grad()
    
    # Compute the gradients
    loss.backward()
    
    # Apply one step of the descent algorithm to update the weights
    optimizer.step()
    
    ## Compute some statistics
    with torch.no_grad():
      running_loss += loss.item()
      running_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Training accuracy:", running_accuracy/float(len(train_setC)),
        "Training loss:", running_loss/float(len(train_setC)), "LWF Loss:", lwf_loss)
  
  epoch_loss.append(running_loss/len(train_setC))
  epoch_acc.append(running_accuracy/len(train_setC))
  
  ### VALIDATION LOOP
  ## Put the network in validation mode
  netC.eval()
  
  running_val_loss = 0
  running_val_accuracy = 0

  for i, batch in enumerate(val_dlC):
    
    with torch.no_grad():
      # Get a batch from the dataloader
      x = batch[0]
      labels = batch[1]

      # move the batch to GPU
      x = x.cuda()
      labels = labels.cuda()

      # Compute the network output
      y= netC(x)
      
      # Compute the loss
      loss = criterion(y, labels)
      
      running_val_loss += loss.item()
      running_val_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Validation accuracy:", running_val_accuracy/float(len(val_setC)),
        "Validation loss:", running_val_loss/float(len(val_setC)))
  
  epoch_val_loss.append(running_val_loss/len(val_setC))
  epoch_val_acc.append(running_val_accuracy/len(val_setC))

torch.save(netC, "modelC.pt")

"""Test Model C"""

# Create a test dataset instance
test_datasetC = SpeechDataset(classes_C, testing_listC)

# Create a DataLoader
test_dlC = torch.utils.data.DataLoader(test_datasetC, batch_size=64)

netC.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(test_dlC):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netC(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_datasetC)),
      "Test loss:", test_loss/float(len(test_datasetC)))

"""Test Model B, A"""

checkpointC = torch.load('modelC.pt')
pretrainedC_dict = checkpointC.speech_model.state_dict()
netB_dict = netB.speech_model.state_dict()
pretrainedC_dict = {k: v for k, v in pretrainedC_dict.items() if k in netB_dict}
netB_dict.update(pretrainedC_dict)
netB.speech_model.load_state_dict(netB_dict)#, strict=False)


netB.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(test_dlB):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netB(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_datasetB)),
      "Test loss:", test_loss/float(len(test_datasetB)))

####-- model A test

checkpointC = torch.load('modelC.pt')
pretrainedC_dict = checkpointC.speech_model.state_dict()
netA_dict = netA.speech_model.state_dict()
pretrainedC_dict = {k: v for k, v in pretrainedC_dict.items() if k in netA_dict}
netA_dict.update(pretrainedC_dict)
netA.speech_model.load_state_dict(netA_dict)#, strict=False)


netA.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(test_dlA):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = netA(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_datasetA)),
      "Test loss:", test_loss/float(len(test_datasetA)))

