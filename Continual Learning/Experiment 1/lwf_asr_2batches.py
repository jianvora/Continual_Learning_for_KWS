# -*- coding: utf-8 -*-
"""LWF ASR_2batches.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aQ2Qny_CiTYFhjc1ctPOlqQi5KB2ra-c

LWF with 2 class split: Dataset A (15 classes) and Dataset B (20 classes)
"""

!pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
import IPython.display as ipd
from tqdm.notebook import tqdm
import random
torch.manual_seed(0)
np.random.seed(0)
random.seed(0)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

"""
import urllib.request

url = 'https://www.cse.iitb.ac.in/~pjyothi/cs753/train_list.txt'
urllib.request.urlretrieve(url, 'train_list.txt')
train_indices = open("/content/train_list.txt").read().splitlines()#.readlines()
train_indices = [int(i) for i in train_indices]
#print(train_indices)
url = 'https://www.cse.iitb.ac.in/~pjyothi/cs753/test_list.txt'
urllib.request.urlretrieve(url, 'test_list.txt')
test_indices = open("/content/test_list.txt").read().splitlines()
test_indices = [int(i) for i in test_indices]
#print(test_indices)
"""

from torchaudio.datasets import SPEECHCOMMANDS
import os
class SubsetSC(SPEECHCOMMANDS):
    def __init__(self, subset: str = None):
        super().__init__("./", download=True)

        def load_list(filename):
            filepath = os.path.join(self._path, filename)
            with open(filepath) as fileobj:
                return [os.path.join(self._path, line.strip()) for line in fileobj]

        if subset == "testing":
            self._walker = load_list("testing_list.txt")
            print("Size of original test set:",len(self._walker))
            #self._walker = [self._walker[i] for i in test_indices]
            #print("Size of new test set:",len(self._walker))
        elif subset == "training":
            excludes = load_list("validation_list.txt") + load_list("testing_list.txt")
            excludes = set(excludes)
            self._walker = [w for w in self._walker if w not in excludes]
            print("Size of original train set:",len(self._walker))
            #self._walker = [self._walker[i] for i in train_indices]
            #print("Size of new train set:",len(self._walker))


# Create training and testing split of the data. We do not use validation in this tutorial.
training_list = SubsetSC("training")
testing_list = SubsetSC("testing")

import os
classes = os.listdir("/content/SpeechCommands/speech_commands_v0.02/")
classes.remove("LICENSE")
classes.remove("README.md")
classes.remove("_background_noise_")
classes.remove("testing_list.txt")
classes.remove("validation_list.txt")
classes.remove(".DS_Store")
print(classes)
old_classes = classes[:-20]
print("Number of classes", len(old_classes))
print(old_classes)

import glob
"""
## Read the test list
with open("/content/SpeechCommands/speech_commands_v0.02/testing_list.txt") as testing_f:
  testing_list = [x.strip() for x in testing_f.readlines()]

print(len(testing_list))
testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_list))
#print("Number of validation samples", len(validation_list))
"""
## Construct a train list
training_list = []

def load_list(filename):
  filepath = os.path.join("/content/SpeechCommands/speech_commands_v0.02/", filename)
  with open(filepath) as fileobj:
    return [os.path.join("/content/SpeechCommands/speech_commands_v0.02/", line.strip()) for line in fileobj]

testing_list = load_list("testing_list.txt")
print(len(testing_list))
old_testing_list = [testing_list[i] for i in range(len(testing_list)) if testing_list[i].split("/")[4] in old_classes ]
#testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(old_testing_list))

excludes = load_list("testing_list.txt") + load_list("validation_list.txt")
excludes = set(excludes)

for c in classes:
  training_list += glob.glob("/content/SpeechCommands/speech_commands_v0.02/" + c + "/*")

training_list = [w for w in training_list if w not in excludes]
old_training_list = [training_list[i] for i in range(len(training_list)) if training_list[i].split("/")[4] in old_classes ]

print("Number of training samples", len(old_training_list))

print(old_testing_list)

class SpeechDataset(SPEECHCOMMANDS):
  
  def __init__(self, classes, file_list):
    super().__init__("/content/", download=True)
    
    self.classes = classes
    
    # create a map from class name to integer
    self.class_to_int = dict(zip(classes, range(len(classes))))
    
    # store the file names
    self.samples = file_list
    #print(self.samples[0])
    
    # store our MFCC transform
    self.mfcc_transform = torchaudio.transforms.MFCC(n_mfcc=12, log_mels=True)
    
  def __len__(self):
    return len(self.samples)
    
  def __getitem__(self,i):
    with torch.no_grad():
      # load a normalized waveform
      waveform,_ = torchaudio.load(self.samples[i], normalization=True)
      
      # if the waveform is too short (less than 1 second) we pad it with zeroes
      if waveform.shape[1] < 16000:
        waveform = F.pad(input=waveform, pad=(0, 16000 - waveform.shape[1]), mode='constant', value=0)
      
      # then, we apply the transform
      mfcc = self.mfcc_transform(waveform).squeeze(0).transpose(0,1)
    
    # get the label from the file name
    label = self.samples[i].split("/")[4]
    
    # return the mfcc coefficient with the sample label
    return mfcc, self.class_to_int[label]

train_set = SpeechDataset(old_classes, old_training_list)
val_set =SpeechDataset(old_classes, old_testing_list)

print(train_set[5][0].shape)

old_train_dl = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)
old_val_dl = torch.utils.data.DataLoader(val_set, batch_size=32)

#print(next(iter(train_dl)))

class CNNLayerNorm(nn.Module):
    def __init__(self, n_feats):
        super(CNNLayerNorm, self).__init__()
        self.layer_norm = nn.LayerNorm(n_feats)

    def forward(self, x):
        # x (batch, channel, feature, time)
        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)
        x = self.layer_norm(x)
        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)

class SpeechRNN(torch.nn.Module):
   
  def __init__(self,kernel = 3, stride = 1, dropout = 0.1, n_feats = 128):#original dropout = 0.5
    super(SpeechRNN, self).__init__()

    self.conv1 = torch.nn.Conv2d(1, 32, kernel, stride, padding = kernel//2)
    #Introduce residual connection here
    #self.layer_norm1 = CNNLayerNorm(n_feats)
    self.layer_norm1 = nn.BatchNorm2d(32)
    self.dropout1 = nn.Dropout(dropout)
    self.conv2 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #self.layer_norm2 = CNNLayerNorm(n_feats)
    self.layer_norm2 = nn.BatchNorm2d(32)
    self.dropout2 = nn.Dropout(dropout)
    self.conv3 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #Introduce residual connection here
    #self.layer_norm3 = CNNLayerNorm(n_feats)
    self.layer_norm3 = nn.BatchNorm2d(32)
    self.dropout3 = nn.Dropout(dropout)
    self.conv4 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #self.layer_norm4 = CNNLayerNorm(n_feats)
    self.layer_norm4 = nn.BatchNorm2d(32)
    self.dropout4 = nn.Dropout(dropout)
    self.conv5 = torch.nn.Conv2d(32, 32, kernel, stride, padding = kernel//2)
    #self.bn5 = nn.BatchNorm2d(32)
    self.dropout5 = nn.Dropout(dropout)

    self.linear = nn.Linear(972*32,256)

    #self.layer_norm5 = nn.LayerNorm(256)

    self.linear1 = torch.nn.Linear(256, 256)
    #self.dropout6 = nn.Dropout(dropout)
    #self.linear2 = torch.nn.Linear(256, len(classes))
    
  def forward(self, x):
    x = x.unsqueeze(1)
    x = self.conv1(x)
    residual = x
    x = self.layer_norm1(x)
    x = F.leaky_relu(x)
    x = self.dropout1(x)
    x = self.conv2(x)
    x = self.layer_norm2(x)
    x = F.leaky_relu(x)
    x = self.dropout2(x)
    x = self.conv3(x)
    x = x + residual

    residual1 = x
    x = self.layer_norm3(x)
    x = F.leaky_relu(x)
    x = self.dropout3(x)
    x = self.conv4(x)
    x = self.layer_norm4(x)
    x = F.leaky_relu(x)
    x = self.dropout4(x)
    x = self.conv5(x)
    x = x + residual1
    #print(x.size())

    sizes = x.size()
    x = x.view(sizes[0], sizes[1]*sizes[2]*sizes[3])
    #x = x.transpose(1,2)
    #print(x.size())
    x = self.linear(x)

    #x = self.layer_norm5(x)
    x = F.leaky_relu(x)

    x = self.linear1(x)
    x = F.leaky_relu(x)
    #x = self.dropout6(x)
    #x = self.linear2(x)
    #print(x.size())
    
    return x

class ModelA(nn.Module):
  def __init__(self,classes):
    super(ModelA,self).__init__()
    self.speech_model = SpeechRNN()
    self.final_layer = torch.nn.Linear(256, len(classes))
  
  def forward(self,x):
    x = self.speech_model(x)
    x = self.final_layer(x)
    return x

#net = SpeechRNN().cuda()
net = ModelA(classes = old_classes).cuda()
print(net)
batch = next(iter(old_train_dl))[0]
print(batch.shape)
y = net(batch.cuda())

print(y.shape)

##RE-RUN THIS CODE TO GET A "NEW" NETWORK

LEARNING_RATE = 0.0005

## Create an instance of our network
net = ModelA(classes = old_classes).cuda()

# Negative log likelihood loss
criterion = torch.nn.CrossEntropyLoss()

# Adam optimizer
optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

from tqdm import tqdm_notebook
## NUMBER OF EPOCHS TO TRAIN
N_EPOCHS = 4

epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []

for e in range(N_EPOCHS):
  
  print("EPOCH:",e)
  
  ### TRAINING LOOP
  running_loss = 0
  running_accuracy = 0
  
  ## Put the network in training mode
  net.train()
  
  for i, batch in enumerate(tqdm_notebook(old_train_dl)):
    
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]
    
    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = net(x)
    
    # Compute the loss
    loss = criterion(y, labels)
    
    # Reset the gradients
    optimizer.zero_grad()
    
    # Compute the gradients
    loss.backward()
    
    # Apply one step of the descent algorithm to update the weights
    optimizer.step()
    
    ## Compute some statistics
    with torch.no_grad():
      running_loss += loss.item()
      running_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Training accuracy:", running_accuracy/float(len(train_set)),
        "Training loss:", running_loss/float(len(train_set)))
  
  epoch_loss.append(running_loss/len(train_set))
  epoch_acc.append(running_accuracy/len(train_set))
  
  ### VALIDATION LOOP
  ## Put the network in validation mode
  net.eval()
  
  running_val_loss = 0
  running_val_accuracy = 0

  for i, batch in enumerate(old_val_dl):
    
    with torch.no_grad():
      # Get a batch from the dataloader
      x = batch[0]
      labels = batch[1]

      # move the batch to GPU
      x = x.cuda()
      labels = labels.cuda()

      # Compute the network output
      y= net(x)
      
      # Compute the loss
      loss = criterion(y, labels)
      
      running_val_loss += loss.item()
      running_val_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Validation accuracy:", running_val_accuracy/float(len(val_set)),
        "Validation loss:", running_val_loss/float(len(val_set)))
  
  epoch_val_loss.append(running_val_loss/len(val_set))
  epoch_val_acc.append(running_val_accuracy/len(val_set))

import numpy  as np
# Create a test dataset instance
test_dataset = SpeechDataset(old_classes, old_testing_list)

# Create a DataLoader
old_test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=64)

net.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(old_test_dl):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = net(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_dataset)),
      "Test loss:", test_loss/float(len(test_dataset)))

print(net)

torch.save(net.state_dict(),'modelA.pth')
torch.save(net,'modelA.pt')

new_classes =classes[-20:]
print("Number of classes", len(new_classes))
print(new_classes)

import glob
"""
## Read the test list
with open("/content/SpeechCommands/speech_commands_v0.02/testing_list.txt") as testing_f:
  testing_list = [x.strip() for x in testing_f.readlines()]

print(len(testing_list))
testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_list))
#print("Number of validation samples", len(validation_list))
"""
## Construct a train list
training_list = []

def load_list(filename):
  filepath = os.path.join("/content/SpeechCommands/speech_commands_v0.02/", filename)
  with open(filepath) as fileobj:
    return [os.path.join("/content/SpeechCommands/speech_commands_v0.02/", line.strip()) for line in fileobj]

testing_list = load_list("testing_list.txt")
print(len(testing_list))
testing_list = [testing_list[i] for i in range(len(testing_list)) if testing_list[i].split("/")[4] in new_classes ]
#testing_list = [testing_list[i] for i in test_indices]
print("Number of testing samples", len(testing_list))

excludes = load_list("testing_list.txt") + load_list("validation_list.txt")
excludes = set(excludes)

for c in classes:
  training_list += glob.glob("/content/SpeechCommands/speech_commands_v0.02/" + c + "/*")

training_list = [w for w in training_list if w not in excludes]
training_list = [training_list[i] for i in range(len(training_list)) if training_list[i].split("/")[4] in new_classes ]
print(training_list[0])
print(testing_list[0])
#training_list = [training_list[i] for i in train_indices]

print("Number of training samples", len(training_list))

train_set = SpeechDataset(new_classes, training_list)
val_set =SpeechDataset(new_classes, testing_list)

print(train_set[5][0].shape)

train_dl = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)
val_dl = torch.utils.data.DataLoader(val_set, batch_size=32)

#print(next(iter(train_dl)))

class ModelB(nn.Module):
  def __init__(self,classes):
    super(ModelB,self).__init__()
    self.speech_model = SpeechRNN()
    self.final_layer = torch.nn.Linear(256, len(classes))
  
  def forward(self,x):
    x = self.speech_model(x)
    x = self.final_layer(x)
    return x

new_net = ModelB(classes = new_classes).cuda()

#print(new_net.state_dict())

checkpoint = torch.load('modelA.pt')
pretrained_dict = checkpoint.speech_model.state_dict()
net1_dict = new_net.speech_model.state_dict()
"""
for key,_ in pretrained_dict.items():
  print(key)
print("/n")
for key,_ in net1_dict.items():
  print(key)
"""
pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in net1_dict}
net1_dict.update(pretrained_dict)
#net1_dict=pretrained_dict
#print(net1_dict)
new_net.speech_model.load_state_dict(net1_dict)#, strict=False)

from copy import deepcopy
from torch.autograd import Variable
from torch.nn import functional as F

def ewc_penalty(old_model:nn.Module, dataset:torch.utils.data.DataLoader):

  params = {n:p for n,p in old_model.named_parameters() if p.requires_grad}
  means = {}
  for n,p in deepcopy(params).items():
    means[n] = Variable(p.data).cuda()
  precision_matrices = {}
  for n,p in deepcopy(params).items():
    p.data.zero_()
    precision_matrices[n] = Variable(p.data).cuda()
  old_model.eval()
  for inp,_ in dataset:
    old_model.zero_grad()
    inp = Variable(inp).cuda()
    #print(old_model(inp))
    output = old_model(inp).view(1,-1)
    label = output.max(1)[1].view(-1)
    #print(label)
    loss = F.nll_loss(F.log_softmax(output,dim=1),label)
    loss.backward()

    for n,p in old_model.named_parameters():
      precision_matrices[n].data+=p.grad.data**2/len(dataset)
  
  precision_matrices = {n:p for n,p in precision_matrices.items()}
  return precision_matrices, means

def lwf(old_model: nn.Module, model:nn.Module,dataset:torch.utils.data.DataLoader):
  loss = 0
  inp = dataset
  #inp = Variable(dataset).cuda()
  #print(inp.shape)
  old_x = old_model(inp)
  x = model(inp)
  #print(x.shape)
  old_x = old_x.view(1,-1)
  x = x.view(1,-1)
  l = torch.dist(old_x,x,p=2)
  #print(l)
  loss+=l.item()
  
  return loss

##RE-RUN THIS CODE TO GET A "NEW" NETWORK

LEARNING_RATE = 0.0005

# Negative log likelihood loss
criterion = torch.nn.CrossEntropyLoss()

# Adam optimizer
optimizer = torch.optim.Adam(new_net.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

from tqdm import tqdm_notebook
## NUMBER OF EPOCHS TO TRAIN
N_EPOCHS = 4
lamda = 0.001

epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []

for e in range(N_EPOCHS):
  
  print("EPOCH:",e)
  
  ### TRAINING LOOP
  running_loss = 0
  running_accuracy = 0
  
  ## Put the network in training mode
  new_net.train()
  
  for i, batch in enumerate(tqdm_notebook(train_dl)):
    
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]
    
    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = new_net(x)
    
    lwf_loss = 0
    lwf_loss = lwf(net.speech_model, new_net.speech_model,x)
    
    # Compute the loss
    loss = criterion(y, labels) + lamda*lwf_loss
    
    # Reset the gradients
    optimizer.zero_grad()
    
    # Compute the gradients
    loss.backward()
    
    # Apply one step of the descent algorithm to update the weights
    optimizer.step()
    
    ## Compute some statistics
    with torch.no_grad():
      running_loss += loss.item()
      running_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Training accuracy:", running_accuracy/float(len(train_set)),
        "Training loss:", running_loss/float(len(train_set)), "LWF Loss:", lwf_loss)
  
  epoch_loss.append(running_loss/len(train_set))
  epoch_acc.append(running_accuracy/len(train_set))
  
  ### VALIDATION LOOP
  ## Put the network in validation mode
  new_net.eval()
  
  running_val_loss = 0
  running_val_accuracy = 0

  for i, batch in enumerate(val_dl):
    
    with torch.no_grad():
      # Get a batch from the dataloader
      x = batch[0]
      labels = batch[1]

      # move the batch to GPU
      x = x.cuda()
      labels = labels.cuda()

      # Compute the network output
      y= new_net(x)
      
      # Compute the loss
      loss = criterion(y, labels)
      
      running_val_loss += loss.item()
      running_val_accuracy += (y.max(1)[1] == labels).sum().item()
    
  print("Validation accuracy:", running_val_accuracy/float(len(val_set)),
        "Validation loss:", running_val_loss/float(len(val_set)))
  
  epoch_val_loss.append(running_val_loss/len(val_set))
  epoch_val_acc.append(running_val_accuracy/len(val_set))

torch.save(new_net, "modelB.pt")

checkpoint1 = torch.load('modelB.pt')
pretrained_dict = checkpoint1.speech_model.state_dict()
net1_dict = net.speech_model.state_dict()
"""
for key,_ in pretrained_dict.items():
  print(key)
print("/n")
for key,_ in net1_dict.items():
  print(key)
"""
pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in net1_dict}
net1_dict.update(pretrained_dict)
#net1_dict=pretrained_dict
#print(net1_dict)
net.speech_model.load_state_dict(net1_dict)#, strict=False)

net.eval()

test_loss = 0
test_accuracy = 0

preds, y_test = np.array([]), np.array([])

for i, batch in enumerate(old_test_dl):

  with torch.no_grad():
    # Get a batch from the dataloader
    x = batch[0]
    labels = batch[1]

    # move the batch to GPU
    x = x.cuda()
    labels = labels.cuda()

    # Compute the network output
    y = net(x)

    # Compute the loss
    loss = criterion(y, labels)
    
    ## Store all the predictions an labels for later
    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])
    y_test = np.hstack([y_test, labels.cpu().numpy()])

    test_loss += loss.item()
    test_accuracy += (y.max(1)[1] == labels).sum().item()

print("Test accuracy:", test_accuracy/float(len(test_dataset)),
      "Test loss:", test_loss/float(len(test_dataset)))